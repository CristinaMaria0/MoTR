---
title: "Exploratory Analysis for MoTR Reading Data"
output: html_notebook
---

```{r}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!

shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))

shhh(library(brms))
shhh(library(bayesplot))
shhh(library(patchwork))
shhh(library(MASS))
shhh(library(tidyr))
shhh(library(extraDistr))
shhh(library(purrr))
# For exercises with Stan code
shhh(library(rstan))
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = FALSE)

shhh(library(car))
shhh(library(coda))
shhh(library(gridExtra))
shhh(library(posterior))
shhh(library(loo))

theme_set(theme_bw())
options(digits=4)
options(scipen=999)
set.seed(444)
pipe_message = function(.data, status) {message(status); .data}

```


# Read in MoTR Data

```{r}

rate = 160

file_prefix = "../data/provo_f160/"
fnames = list.files(path=file_prefix)

df = data.frame()
for (f in fnames) {
  temp = read.csv(paste0(file_prefix, "/", f)) %>%
    mutate(subj = str_remove(f, "_reading_measures.csv"))
  df = rbind(df, temp)
}

# Filter out readers whose accuracy to the comprehension questions were less than 80%.
filter_df = df %>%
  group_by(para_nr, subj) %>% summarise(correct = if_else(unique(correctness) == 1, 1, 0)) %>% ungroup() %>%
  drop_na() %>%
  group_by(subj) %>% summarise(p_correct = mean(correct)) %>% ungroup() %>%
  mutate(p_correct = round(p_correct, digits = 2))

filter_df = filter_df %>% filter(p_correct < 0.8)
filter_list = filter_df$subj
pilot_exceptions <- c("reader_255", "reader_256", "reader_259", "reader_261", "reader_262", "reader_263")

raw_df = df %>%
  filter(! subj %in% c(filter_list) | (subj %in% pilot_exceptions)) %>%
  mutate(word = str_trim(word)) %>%
  mutate(subj = str_remove(subj, "reader_")) %>%
  mutate(subj = as.character(subj)) %>%
  mutate(FPReg = if_else(total_duration == 0, -1, FPReg)) %>% #If the word is skipped we can't say that it wasn't regressed on the first pass. Set to a "NA"
  mutate(skip = if_else(FPFix == 1, 0, 1)) %>% # use the same defination as in provo paper
  dplyr::select(subj, expr_id, cond_id, para_nr, word, word_nr, first_duration, total_duration, gaze_duration, go_past_time, FPReg, skip) %>%
  gather(metric, value, 7:10) %>%
  group_by(para_nr, subj, metric, cond_id, expr_id) %>%
  mutate(fixed = if_else(value > 0, 1, 0),
         n_fixed = sum(fixed),
         n_words = n()) %>%
    ungroup() %>%
  mutate(fix_threshold = n_fixed > (n_words / 5)) %>%
  mutate(skimming = if_else(fix_threshold == F,T, F)) %>%
  filter(skimming == F) %>%
  spread(metric, value) %>%
  dplyr::select(-fixed, -n_fixed, -n_words, -fix_threshold, -skimming)
length(unique(raw_df$subj))
# View(raw_df)

df %>%
  filter(! subj %in% c(filter_list) | (subj %in% pilot_exceptions)) %>%
  filter(FPReg >= 0) %>%
  dplyr::select(FPReg) %>%
  drop_na() %>%
  summarise( m = mean(FPReg))

df %>%
  filter(! subj %in% c(filter_list) | (subj %in% pilot_exceptions)) %>%
  dplyr::select(FPFix) %>%
  drop_na() %>%
  summarise( m = mean(FPFix))



```


```{r}
# Average across subjects
motr_agg_df = raw_df %>%
  gather(metric, value, 7:12) %>%
    filter(value >= 0) %>% #Removes the "NA" values for FPReg
  
    # ==== Remove skipped words
    mutate(zero = if_else(!metric %in% c("FPReg", "skip") & value == 0,T, F)) %>%
    filter(zero == F) %>%
  
    drop_na() %>%
    group_by(para_nr, word_nr, word, metric) %>%
    
    # === Remove outliers > 3SD
      # mutate(outlier = if_else(metric != "FPReg" & value > (mean(value) + 3 * sd(value)), T, F)) %>% filter(outlier == F) %>%
  
      summarise(value = mean(value), nsubj = length(unique(subj))) %>%
  ungroup() %>%
  arrange(para_nr, word_nr) %>%
  rename(text_id = para_nr, word_text_idx = word_nr, motr_value = value)

```




# Comparison to Provo


```{r}
# Read in Provo surprisal, frequency and length data
provo_modeling_df = read.csv("../data/provo_stats.csv") %>%
  dplyr::select(text_id, sent_id, trigger_idx, word, freq, surp, len) %>%
  rename(word_idx = trigger_idx)

provo_modeling_df

```

```{r}
# Read in Provo eyetracking data

provo_raw_df = read.csv("../data/provo_eyetracking.csv")

```

```{r}

# unique(provo_raw_df$Participant_ID)
# length(unique(provo_raw_df$Participant_ID))

provo_eyetracking_df = provo_raw_df %>%
  dplyr::select(Participant_ID, Text_ID, Sentence_Number, Word_In_Sentence_Number, Word, Word_Number, IA_FIRST_FIX_PROGRESSIVE, IA_FIRST_RUN_DWELL_TIME, IA_DWELL_TIME, IA_REGRESSION_PATH_DURATION, IA_REGRESSION_OUT, IA_SKIP) %>%
  rename( #first_duration = IA_FIRST_FIXATION_DURATION,   
          gaze_duration = IA_FIRST_RUN_DWELL_TIME,
          total_duration = IA_DWELL_TIME,
          go_past_time = IA_REGRESSION_PATH_DURATION,
          subj = Participant_ID,
          text_id = Text_ID,
          sent_id = Sentence_Number,
          word_idx = Word_In_Sentence_Number,
          word_text_idx = Word_Number,   # IA_ID?
          word = Word,      # Word?
          FPReg = IA_REGRESSION_OUT,
          skip = IA_SKIP,
          ff_progressive = IA_FIRST_FIX_PROGRESSIVE) %>%
  mutate(first_duration = gaze_duration) %>%
  mutate(gaze_duration = if_else(ff_progressive == 0, 0, as.double(gaze_duration)),
         go_past_time = if_else(ff_progressive == 0, 0, as.double(go_past_time))) %>%
  dplyr::select(-ff_progressive) %>%
  
  mutate(
    gaze_duration = if_else(total_duration == 0, 0, as.double(gaze_duration)),
      go_past_time = if_else(total_duration == 0, 0, as.double(go_past_time)),
      FPReg = if_else(total_duration == 0, -1, as.double(FPReg)),
      first_duration =  if_else(total_duration == 0, 0, as.double(first_duration)),
  ) %>%
  gather(metric, value, 7:12) %>%
  filter(value >= 0) %>%          # filter skipped word in eye tracking data for FPReg
  
  # ==== Remove skipped words
  mutate(zero = if_else(metric != "FPReg" & value == 0,T, F)) %>%
  filter(zero == F) %>%
  
  # mutate(value = if_else(is.na(value), as.integer(0), as.integer(value))) %>%
  # mutate(value = if_else(metric != "FPReg" & is.na(value), as.integer(0), as.integer(value))) %>%
  drop_na() %>%
  mutate(word = str_trim(word)) %>%
  mutate(subj = str_remove(subj, "Sub")) %>%
  mutate(subj = as.integer(subj)) %>%
    group_by(text_id, word_text_idx, sent_id, word_idx, word, metric) %>%
  
  # === Remove outliers > 3SD
    # mutate(outlier = if_else(! metric %in% c("FPReg", "skip") & value > (mean(value) + 3 * sd(value) ), T, F)) %>%
    # filter(outlier == F) %>%
  
  ungroup() #%>%

# Aggregate cross-participant data for all subjects
provo_eyetracking_agg_df = provo_eyetracking_df %>%
  group_by(text_id, word_text_idx, sent_id, word_idx, word, metric) %>%
    summarise(value = mean(value),
              nsubj = length(unique(subj))) %>%
    ungroup()

provo_raw_df %>%
  dplyr::select(IA_REGRESSION_OUT) %>%
  drop_na() %>%
  summarise( m = mean(IA_REGRESSION_OUT))

provo_raw_df %>%
  dplyr::select(IA_SKIP) %>%
  drop_na() %>%
  summarise( m = mean(IA_SKIP))

```

```{r}

# Split the eyetracking data in two by subjects to see how well it correlates with itself
provo_eyetracking_subj1_df_temp = provo_eyetracking_df %>%
  filter(subj <= 42) %>%
  mutate(word_text_idx = as.integer(word_text_idx - 1)) %>%
  group_by(text_id, word_text_idx, sent_id, word_idx, word, metric) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
  rename(value_1 = value) #%>%
  # dplyr::select(-sent_id, -word_idx)


provo_eyetracking_subj1_df = merge(provo_eyetracking_subj1_df_temp, motr_agg_df, by=c("text_id", "word_text_idx", "metric")) %>%
  arrange(text_id, sent_id, word_idx) %>%
  filter(!(text_id == 13 & word_text_idx >= 20 & word_text_idx <= 52)) %>%
  filter(!(text_id == 3 & word_text_idx >= 46 & word_text_idx <= 57)) %>%
  rename(word = word.y) %>%
  dplyr::select(text_id, word_text_idx, metric, word, value_1) 

# View(provo_eyetracking_subj1_df)

provo_eyetracking_subj2_df = provo_eyetracking_df %>%
  filter(subj > 42) %>%
  mutate(word_text_idx = as.integer(word_text_idx - 1)) %>%
  group_by(text_id, word_text_idx, sent_id, word_idx, word, metric) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
    rename(value_2 = value)%>%
  dplyr::select(-sent_id, -word_idx)

# View(provo_eyetracking_subj2_df)
  
provo_eyetr_grouped_df = merge(provo_eyetracking_subj2_df, provo_eyetracking_subj1_df, by=c("text_id", "word_text_idx", "metric")) %>%
  # filter(word.x == word.y) %>%
  dplyr::select(-word.y) %>%
  # === Remove outliers > 3SD
  # group_by(metric) %>%
  #   mutate(motr_outlier = if_else(! metric %in% c("FPReg", "skip") & value_1 > (mean(value_1) + 3 * sd(value_1) ), T, F)) %>%
  #   filter(motr_outlier == F) %>%
  #   mutate(eyetr_outlier = if_else(! metric %in% c("FPReg", "skip") & value_2 > (mean(value_2) + 3 * sd(value_2) ), T, F)) %>%
  #   filter(eyetr_outlier == F) %>%
  # ungroup() %>%
  
  gather(measure, value, c("value_1", "value_2")) #%>%
  # dplyr::select(-motr_outlier, -eyetr_outlier)

# View(provo_eyetr_grouped_df)

```


```{r}
provo_df = merge(provo_eyetracking_agg_df, provo_modeling_df, by=c("text_id", "sent_id", "word_idx")) %>%
  mutate(word_text_idx = as.integer(word_text_idx - 1)) %>%
  arrange(text_id, sent_id, word_idx) %>%
  rename(eyetr_value = value) 

provo_df = merge(provo_df, motr_agg_df, by=c("text_id", "word_text_idx", "metric")) %>%
arrange(text_id, sent_id, word_idx) %>%
  # almost all the word.x != word.y is because of normalization problem, so we can keep them, instead, deleting some special cases
filter(!(text_id == 13 & word_text_idx >= 20 & word_text_idx <= 52)) %>%
  filter(!(text_id == 3 & word_text_idx >= 46 & word_text_idx <= 57)) %>%
# filter(word.x == word) #%>%
dplyr::select(-word.x, -word.y) %>%
  
# === Remove outliers > 3SD
# group_by(metric) %>%
#   mutate(motr_outlier = if_else(! metric %in% c("FPReg", "skip") & motr_value > (mean(motr_value) + 3 * sd(motr_value) ), T, F)) %>%
#   filter(motr_outlier == F) %>%
#   mutate(eyetr_outlier = if_else(! metric %in% c("FPReg", "skip") & eyetr_value > (mean(eyetr_value) + 3 * sd(eyetr_value) ), T, F)) %>%
#   filter(eyetr_outlier == F) %>%
# ungroup() %>%
  
gather(measure, value, c("eyetr_value", "motr_value")) #%>%
# dplyr::select(-motr_outlier, -eyetr_outlier)
  
# provo_df
  
```


# Bayesian -- brm & gams -- surprisal & RTs
```{r}
# View(provo_df)

gam_modeling_df = provo_df %>%
  spread(measure, value) %>%
  # mutate(len = nchar(word)) %>%  # len has already exists, but do not count punct into len.
  group_by(metric, sent_id, text_id) %>%
    arrange(word_text_idx) %>%
    mutate(prev_surp = lag(surp),
           prev2_surp = lag(prev_surp),
           prev_freq = lag(freq),
           prev2_freq = lag(prev_freq),
           prev_len = lag(len),
           prev2_len = lag(prev_len),
           prev_eyetr_value = lag(eyetr_value)) %>%
  ungroup() %>%
  drop_na() %>%
  rename(psychometric = motr_value)# %>%
  # filter(psychometric > 0)
View(gam_modeling_df)

gam_modeling_df %>%
  filter(metric == "gaze_duration") %>%
  arrange(text_id, sent_id, word_idx) 

gam_modeling_df %>% 
  ggplot(aes(x = psychometric)) +
  geom_density() +
  facet_wrap(~metric, scales = "free") +
  theme_bw() +
  scale_fill_brewer(palette = "Set1")

```

## Shape of surprisal / RT relationship
```{r}

## log normal distr
priors <- c(
  prior(normal(6, 1), class = Intercept),
  prior(normal(0, 0.5), class = b),
  prior(normal(0, 2), class = sds),
  prior(normal(0, 1), class = sigma)
)

## gamma distr
priors_gamma <- c(
  prior(normal(6, 1), class = Intercept),
  prior(normal(0, 0.5), class = b),
  prior(cauchy(0, 0.5), class = sds),
  prior(exponential(2), class = shape)
)

fit_gam_inner = function(bootstrap_sample, mean_predictors, target_prev_word, metric, is_bootstrap) {
  df = if (is_bootstrap) {
    analysis(bootstrap_sample)  # Apply analysis for bootstrap samples
  } else {
    bootstrap_sample  
  }

  # m = gam(psychometric ~ s(surp, bs = 'cr', k = 20) + s(prev_surp, bs = 'cr', k = 20) + te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr'), data = df, method = 'REML')
  m <- brm(
    # psychometric ~ s(surp, bs = 'cr', k = 6) + s(prev_surp, bs = 'cr', k = 6) + t2(freq, len, bs = 'cr') + t2(prev_freq, prev_len, bs = 'cr'),
    psychometric ~ surp + prev_surp + t2(freq, len, bs = 'cr') + t2(prev_freq, prev_len, bs = 'cr'),
    data = df,
    # family = lognormal(),
    family = Gamma(link = "log"),
    prior = priors_gamma,
    cores = 8,
    seed = 444,
    chain = 4,
    iter = 4000,
    file = if (is_bootstrap) {
    paste0("./bayesian_models/bayesian_models_surprisal/drop0s_feb25/feb25_gamma_provo_", metric, "_", bootstrap_sample$id)
    # paste0("./bayesian_models/bayesian_models_surprisal/linear_drop0s_feb25/feb25_gamma_provo_", metric, "_linear_", bootstrap_sample$id)
  } else {
    paste0("./bayesian_models/bayesian_models_surprisal/drop0s_feb25/feb25_gamma_provo_", metric, "_0")
    # paste0("./bayesian_models/bayesian_models_surprisal/linear_drop0s_feb25/feb25_gamma_provo_", metric, "_linear_0")
  },
    backend = "cmdstanr",
    control = list(adapt_delta = 0.99)
    )
  
  if(target_prev_word == F) {
    newdata = data.frame(surp=seq(0,20,by=0.1), prev_surp=mean_predictors$surp,
                         freq=mean_predictors$freq, prev_freq=mean_predictors$freq,
                         len=mean_predictors$len, prev_len=mean_predictors$len)

    all_term_predictions = predict(m, newdata=newdata, summary = TRUE)#[, "Estimate"] - pred_mean[1, "Estimate"]
    # View(all_term_predictions)

  } else {
    newdata = data.frame(surp=mean_predictors$surp, prev_surp=seq(0,20,by=0.1),
                         freq=mean_predictors$freq, prev_freq=mean_predictors$freq,
                         len=mean_predictors$len, prev_len=mean_predictors$len)

    all_term_predictions = predict(m, newdata=newdata, summary = TRUE)#[, "Estimate"] - pred_mean[1, "Estimate"]
    # View(all_term_predictions)
  }


    predictions = all_term_predictions[, "Estimate"] #- pred_mean[1, "Estimate"]
  
  
  return( newdata %>% mutate(y = predictions))
}

fit_gam = function(df, mean_predictors, target_prev_word, metric, alpha=0.05) {
   # Fit a GAM with original data
  # original_data_models = fit_gam_inner(df, mean_predictors, target_prev_word, metric, is_bootstrap = FALSE)
  boot_models = df %>% bootstraps(times=20) %>% 
   # Fit a GAM and get predictions for each bootstrapped sample
    mutate(smoothed=map(splits, fit_gam_inner, mean_predictors=mean_predictors, target_prev_word=target_prev_word, metric=metric, is_bootstrap = TRUE))
   # Combine original data results with bootstrap results
  # boot_models = bind_rows(list(original_data = list(smoothed = list(original_data_models)), boot_models))
  
  # Extract mean and 5% and 95% percentile y-values for each surprisal value
  if(target_prev_word == F) {
    
    result = boot_models %>% 
      unnest(smoothed) %>% 
      dplyr::select(surp, y) %>%
      group_by(surp) %>%
        summarise(y_lower=quantile(y, alpha / 2), 
                  y_upper=quantile(y, 1 - alpha / 2),
                  y=mean(y)) %>% 
      ungroup()
  } else {
    
    result = boot_models %>% 
      unnest(smoothed) %>% 
      dplyr::select(prev_surp, y) %>%
      group_by(prev_surp) %>%
        summarise(y_lower=quantile(y, alpha / 2), 
                  y_upper=quantile(y, 1 - alpha / 2),
                  y=mean(y)) %>%
      ungroup() %>%
      rename(surp = prev_surp)
  }
  # View(result)
  return (result)
}

```



```{r, eval=FALSE}

smooths_df = data.frame()

metrics = c("gaze_duration", "total_duration", "go_past_time")
# metrics = c("go_past_time")
for (m in metrics) {
  for( tval in c(T,F)) {
    print(paste0("Fitting model for ", m))
    dummy_df = gam_modeling_df %>% filter(metric == m) %>%
      mutate(psychometric =  pmax(psychometric, 1))
    # View(dummy_df)
    mean_predictors = dummy_df %>% summarise(surp = mean(surp), len = mean(len), freq = mean(freq))
    # View(mean_predictors)
    smooths = dummy_df %>% fit_gam(., mean_predictors, target_prev_word = tval, metric = m)
    #Fix 0 surprisal = 0 mse
    gam_smooths = smooths %>% mutate(delta = 0 - y[1], y=y + delta, y_lower= y_lower + delta, y_upper=y_upper + delta)
    smooths_df = rbind(smooths_df, gam_smooths %>% mutate(psychometric = m, prev_word = tval))
    # View(smooths_df)
  }
}

```

### Get Density Data
```{r}
get_d_points = function(df) {
    x = density(df$surp)$x
    y = density(df$surp)$y
    return(data.frame(x, y))
  }

density_data = data.frame()

for(m in c("gaze_duration", "total_duration", "go_past_time")) {
  dummy_df = provo_df %>% filter(metric == m) %>%
      do({get_d_points(.)}) %>%
      filter(x>0, x<20)
  density_data = rbind(density_data, dummy_df %>% mutate(metric=m))
}

```


```{r}
plotting_df = smooths_df %>%
  mutate(target_word = if_else(prev_word == F, "wt", "wt-1"))
write.csv(plotting_df, "../data/gamma_provo_surprisal_bayesian_feb25.csv", row.names = FALSE)
```


```{r}
vnames <-list(
  "gaze_duration" = "Gaze Duration",
  "go_past_time" = "Go Past Time",
  "total_duration" = "Total Duration",
  'wt-1' = bquote(w[t-1]),
  'wt' = bquote(w[t])
)

vlabeller <- function(variable,value){
  return(vnames[value])
}

plotting_nonlinear_df <- read.csv("../data/gamma_provo_surprisal_bayesian_feb25.csv")
plotting_linear_df <- read.csv("../data/gamma_provo_surprisal_bayesian_feb25_linear.csv")

plotting_nonlinear_df$model_type <- 'Nonlinear'
plotting_linear_df$model_type <- 'Linear'

plotting_combined_df <- rbind(plotting_nonlinear_df, plotting_linear_df)

ggplot(plotting_combined_df, aes(x=surp, y=y)) +
  # First, plot "Linear" model data in grey
  geom_line(data = subset(plotting_combined_df, model_type == "Linear"), 
            aes(x=surp, y=y, group = interaction(psychometric, target_word), linetype= target_word), color = "grey", size=0.7) +
  geom_ribbon(data = subset(plotting_combined_df, model_type == "Linear"), 
              aes(x=surp, ymin=y_lower, ymax=y_upper), fill = "grey", alpha=0.3, size=0.5) +
  
  geom_line(data = subset(plotting_combined_df, model_type == "Nonlinear"), 
            aes(color = psychometric, linetype = target_word), size=0.7) +
  geom_ribbon(data = subset(plotting_combined_df, model_type == "Nonlinear"), 
              aes(x=surp, ymin=y_lower, ymax=y_upper, fill = psychometric), alpha=0.5, size=0.5) +
  
  # Density Data
  annotate("rect", xmin=-5, xmax=25, ymin=-25, ymax=-13, fill="white", color="grey", alpha=1, size = 0) +
  geom_line(data = density_data, aes(x=x, y=y*100 - 25), size = 0.2, color="#aaaaaa") +
  geom_ribbon(data = density_data, aes(x=x, ymin=-50, ymax=y*100 - 25), color="#dadeea", alpha = 0.1) +
  
  geom_hline(yintercept = -13, color = "black", size = 0.1) +
  scale_x_continuous(labels=c(0, 10, 20), breaks=c(0, 10, 20), minor_breaks = NULL) +
  facet_wrap(psychometric~target_word, nrow = 1, labeller = vlabeller) +
  ylab("Slowdown due to Surprisal (ms)") +
  xlab("Surprisal of Word") +
  coord_cartesian(ylim = c(-20, 100), xlim = c(0, 20)) +
  theme(panel.grid.minor = element_blank(), legend.position = "none")

# # Surprisal curves
#   ggplot() +
#       # Surrp / Rt data
#       # geom_line(data = smooths_df, aes(x=prev_surp, y=y, color = psychometric), size=0.7) +
#       geom_line(data = plotting_combined_df, aes(x=surp, y=y, color = psychometric, linetype=target_word),  size=0.7) +
#       # geom_ribbon(data = smooths_df, aes(x=prev_surp, ymin=y_lower, ymax=y_upper, fill = psychometric), alpha=0.3, size=0.5) +
#       geom_ribbon(data = plotting_combined_df, aes(x=surp, ymin=y_lower, ymax=y_upper, fill = psychometric), alpha=0.3, size=0.5) +
#       # Density Data
#       annotate("rect", xmin=-5, xmax=25, ymin=-25,ymax=-13, fill="white", color="grey", alpha=1, size = 0) +
#       geom_line(data = density_data, aes(x=x, y=y*100 - 25), size = 0.2, color="#aaaaaa") +
# 
#       geom_ribbon(data = density_data, aes(x=x, ymin=-50, ymax=y*100 - 25), color="#dadeea", alpha = 0.1) +
# 
#       geom_hline(yintercept = -13, color = "black", size = 0.1) +
# 
#       scale_x_continuous(labels=c(0, 10, 20), breaks=c(0, 10, 20), minor_breaks = NULL) +
#       facet_wrap(psychometric~target_word, nrow = 1, labeller = vlabeller) +
#       ylab("Slowdown due to Surprisal (ms)") +
#       xlab("Surprisal of Word") +
#       coord_cartesian(ylim = c(-20, 100), xlim = c(0, 20)) +
#       # ggtitle("MoTR Times and Previous Word Surprisal")
#   theme(
#     legend.position = "none",
#     panel.grid.minor = element_blank()
#   )
  
ggsave("../visualizations/surp_rt_wt_combo.pdf", device = "pdf", width = 6, height = 2.5)


```

# Surprisal link analysis -- linear & nonlinear model comparison

```{r}
model_gd_linear <- readRDS("bayesian_models/bayesian_models_surprisal/linear_drop0s_feb25/feb25_gamma_provo_gaze_duration_linear_0.rds")

model_gd_nonlinear <- readRDS("bayesian_models/bayesian_models_surprisal/drop0s_feb25/feb25_gamma_provo_gaze_duration_0.rds")

model_gpt_linear <- readRDS("bayesian_models/bayesian_models_surprisal/linear_drop0s_feb25/feb25_gamma_provo_go_past_time_linear_0.rds")

model_gpt_nonlinear <- readRDS("bayesian_models/bayesian_models_surprisal/drop0s_feb25/feb25_gamma_provo_go_past_time_0.rds")

model_td_linear <- readRDS("bayesian_models/bayesian_models_surprisal/linear_drop0s_feb25/feb25_gamma_provo_total_duration_linear_0.rds")

model_td_nonlinear <- readRDS("bayesian_models/bayesian_models_surprisal/drop0s_feb25/feb25_gamma_provo_total_duration_0.rds")

```

# leave-one-out cross validation

Results: The Pareto k estimates < 0.5 for all models suggesting the estimates are reliable.

For all the three pairs of model fit, a linear model has higher elpd_loo, which is the sum of the pointwise predictive accuracy, indicating the model with a linear term for surp and prev_surp can explain the data better.

p_loo shows the fitted model complexity. It is true that all the non-linear models have higher p_loo values. They are more complicated and flexible.

looic is similar to elpd_loo

```{r}
loo_gd_linear <- loo(model_gd_linear)
loo_gd_linear

loo_gd_nonlinear <- loo(model_gd_nonlinear)
loo_gd_nonlinear 

loo_gpt_linear <- loo(model_gpt_linear)
loo_gpt_linear

loo_gpt_nonlinear <- loo(model_gpt_nonlinear)
loo_gpt_nonlinear

loo_td_linear <- loo(model_td_linear)
loo_td_linear

loo_td_nonlinear <- loo(model_td_nonlinear)
loo_td_nonlinear

```

These comparisons tell the same messages as above, but more direct. 
Using linear term for surp and prev_surp would have higher predictive accuracy, e.g. 1.7, 1.4, 1.4, respectively, but the difference is smaller than 4 (suggesting a very small difference) and is smaller than two SE for some the models. So, there is no significant difference between linear and non-linear model.
* When the model fitting data drop 0s, the results are similar. The elpd_diffs are bigger than 4, but still within 2SE.

```{r}
loo_compare(loo_gd_linear, loo_gd_nonlinear)
loo_compare(loo_gpt_linear, loo_gpt_nonlinear)
loo_compare(loo_td_linear, loo_td_nonlinear)
```

