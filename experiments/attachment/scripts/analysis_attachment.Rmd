---
title: "Exploratory Analysis for MoTR Reading Data"
output: html_notebook
---

```{r}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!

shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))

shhh(library(brms))
shhh(library(bayesplot))
shhh(library(MASS))
shhh(library(tidyr))
shhh(library(purrr))


theme_set(theme_bw())
options(digits=4)
options(scipen=999)
set.seed(444)
pipe_message = function(.data, status) {message(status); .data}

```


# Read in MoTR Data

```{r}

rate = 160

# Please change this path accordingly
file_prefix = paste0("/Users/cui/Desktop/motr_lc_", as.character(rate),"/")       
fnames = list.files(path=file_prefix)

# Read in the data
df = data.frame()
for (f in fnames) {
  temp = read.csv(paste0(file_prefix, "/", f)) %>%
    mutate(subj = str_remove(f, "_reading_measures.csv"))
  df = rbind(df, temp)
}

filter_df = df %>%
  group_by(para_nr, subj) %>%
    summarise(correct = if_else(unique(correctness) == 1, 1, 0)) %>%
  ungroup() %>%
  drop_na() %>%
  group_by(subj) %>%
    summarise(p_correct = mean(correct)) %>%
  ungroup() %>%
  mutate(p_correct = round(p_correct, digits = 2))

filter_df = filter_df %>% filter(p_correct < 0.8)
filter_list = filter_df$subj
subj_list = unique(df$subj)
print(length(subj_list))

raw_df = df %>%
  filter(! subj %in% c(filter_list)) %>%
  mutate(subj = str_remove(subj, "reader_")) %>%
  mutate(subj = as.integer(subj)) %>%
  filter(! subj %in% c(118, 119, 120, 107, 103, 130, 6, 19, 26, 262, 276, 28, 294, 334, 338, 353, 373, 385) ) %>%
  dplyr::select(expr_id, cond_id, para_nr, word, word_nr, first_duration, total_duration, gaze_duration, go_past_time, FPReg, subj, sent_rg_id, sent_rg)

raw_df


```

```{r, warning=F}

motr_df = raw_df %>%
  gather(metric, value, 6:10) %>%
  mutate(condition = case_when(
    cond_id == 1 ~ "high", # Really, "no-comma"
    cond_id == 2 ~ "low", # Really, "comma"
    cond_id == 3 ~ "high",
    cond_id == 4 ~ "low",
    cond_id == 5 ~ "high",
    cond_id == 6 ~ "low",
    cond_id == 8 ~ "filler"
  )) %>%
  mutate(experiment = case_when(
    cond_id %in% c(1, 2) ~ "Coordination",
    cond_id %in% c(3, 4) ~ "Adverb",
    cond_id %in% c(5, 6) ~ "Relative Clause",
    cond_id %in% c(8) ~ "Filler"
  )) %>%
  rename(item_id = para_nr) %>%
  dplyr::select(-cond_id, -expr_id) %>%
  filter(experiment != "Filler") %>%
  
  # Filter out sentences where the participant focuses on less than 1/5 of the total words, i.e. where they are skimming
  group_by(item_id, subj, metric, condition, experiment) %>%
    mutate(fixed = if_else(value > 0, 1, 0),
           fixed = if_else(metric == "FPReg", 1, fixed),
           n_fixed = sum(fixed),
           n_words = n()) %>%
  ungroup() %>%
  mutate(fix_threshold = n_fixed > (n_words / 5)) %>%
  mutate(skimming = if_else(fix_threshold == F,T, F)) %>%
  
  #Filter out words that are more than 3 SDs away from the mean of their reading time
  group_by(metric) %>%
    mutate(outlier = value > (mean(value) + 3 * sd(value))) %>%
  ungroup() %>%
  mutate(outlier_discard = if_else(metric %in% c("first_duration", "gaze_duration", "total_duration", "go_past_time") & outlier == T, F, T)) %>%
  filter(outlier_discard == T) %>%
  drop_na() %>%
  
    # Finally, filter out all the sentences that were skimmed
  filter(skimming == F) %>%
  dplyr::select(-fixed, -n_fixed, -n_words, -fix_threshold, -skimming, -outlier)

motr_clean_df = motr_df %>%
  
  #Filter out sentence regions with a reading-time of zero
  mutate(zero = if_else(metric != "FPReg" & value == 0,T, F)) %>%
  filter(zero == F) %>%
  dplyr::select(-zero) %>%
  group_by(subj, experiment, condition, item_id, sent_rg_id, metric) %>%
      summarise(value = if_else(metric == "FPReg", as.double(any(value)), mean(value))) %>%
  ungroup() %>%
  mutate(measure = "MoTR")
View(motr_clean_df)

motr_agg_df = motr_clean_df %>%
  group_by(experiment, condition, item_id, sent_rg_id, metric, measure) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
  spread(condition, value) %>%
  mutate(diff = high - low) %>%
  drop_na() %>%
  group_by(experiment, sent_rg_id, metric, measure) %>%
    summarise( m = mean(diff),
               sd = std.error(diff),
               upper = m + 1.96 * sd,
               lower = m - 1.96 * sd) %>%
  ungroup()

```

```{r}

# Read in eye-tracking data

eyetr_agg_df = read.csv("../data/witzel_eyetr_data.csv") %>%
  mutate(Region_Order = Region_Order - 1) %>%
  mutate(Condition = if_else(Condition == "Hight attachment", "High attachment", Condition)) %>%
  mutate(Condition = if_else(Condition == "Ambiguous", "High attachment", Condition),
         Condition = if_else(Condition == "Unambiguous", "Low attachment", Condition)) %>%
  spread(Condition, Value) %>%
  mutate(m = `High attachment` - `Low attachment`) %>%
  
  rename(experiment = Study, metric = Metric, sent_rg_id = Region_Order) %>%
  dplyr::select(-`High attachment`, -`Low attachment`, -Region) %>%
  mutate(sd = 0,
         upper = m,
         lower = m,
         measure = "Eye Tracking")

```

```{r}
# Read in Maze and SPR Data
amaze_df = read_rds("../data/a_maze.rds")
gmaze_df = read_rds("../data/g_maze.rds")
spr_df = read_rds("../data/spr.rds")
```

```{r}

# Get region number, word numebr alignment
region_reference_df = motr_df %>%
  dplyr::select(item_id, word, word_nr, sent_rg_id, sent_rg) %>%
  unique()


```


```{r}
# G-Maze Data

gmaze_clean_df = gmaze_df %>%
  rename(condition = type, item_id = group, word_nr = word_num, value = rt, subj = subject) %>%
  dplyr::select(condition, item_id, word_nr, value, subj, word) %>%
  merge(region_reference_df, by = c("item_id", "word", "word_nr")) %>%
  filter(! condition %in% c("filler", "practice")) %>%
  drop_na() %>%
  mutate(outlier = value > (mean(value) + 3 * sd(value))) %>%
  filter(outlier == F) %>%
  mutate(experiment = case_when(
    condition %in% c("adverb_high", "adverb_low") ~ "Adverb",
    condition %in% c("and_comma", "and_no_comma") ~ "Coordination",
    condition %in% c("relative_high", "relative_low") ~ "Relative Clause")
  ) %>%
  mutate(condition = case_when(
    condition %in% c("adverb_high", "relative_high", "and_no_comma") ~ "high",
    condition %in% c("adverb_low", "relative_low", "and_comma") ~ "low")
  ) %>%
  drop_na() %>%
  group_by(subj, item_id, condition, sent_rg_id, experiment) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
  mutate(measure = "G-Maze",
         metric = "go_past_time") %>%
  mutate(zero = if_else(value == 0,T, F)) %>%
  filter(zero == F) %>%
  dplyr::select(-zero)

gmaze_agg_df = gmaze_clean_df %>%
  group_by(item_id, condition, sent_rg_id, experiment, metric, measure) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
  spread(condition, value) %>%
  mutate(diff = high -low) %>%
  group_by(sent_rg_id, experiment, measure, metric) %>%
    summarise(m = mean(diff),
              sd = std.error(diff),
              lower = m - 1.96 * sd,
              upper = m + 1.96 * sd) %>%
  ungroup()

# View(gmaze_clean_df)


```

```{r}
# A-Maze Data

amaze_clean_df = amaze_df %>%
  rename(condition = type, item_id = group, word_nr = word_num, value = rt, subj = subject) %>%
  dplyr::select(condition, item_id, word_nr, value, subj, word) %>%
  merge(region_reference_df, by = c("item_id", "word", "word_nr")) %>%
  filter(! condition %in% c("filler", "practice")) %>%
  drop_na() %>%
  mutate(outlier = value > (mean(value) + 3 * sd(value))) %>%
  filter(outlier == F) %>%
  mutate(experiment = case_when(
    condition %in% c("adverb_high", "adverb_low") ~ "Adverb",
    condition %in% c("and_comma", "and_no_comma") ~ "Coordination",
    condition %in% c("relative_high", "relative_low") ~ "Relative Clause")
  ) %>%
  mutate(condition = case_when(
    condition %in% c("adverb_high", "relative_high", "and_no_comma") ~ "high",
    condition %in% c("adverb_low", "relative_low", "and_comma") ~ "low")
  ) %>%
  drop_na() %>%
  group_by(subj, item_id, condition, sent_rg_id, experiment) %>%
    summarise(value = mean(value)) %>%
  ungroup()%>%
  mutate(measure = "A-Maze",
         metric = "go_past_time")

amaze_agg_df = amaze_clean_df %>%
  group_by(item_id, condition, sent_rg_id, experiment, metric, measure) %>%
    summarise(value = mean(value)) %>%
  ungroup()%>%
  spread(condition, value) %>%
  mutate(diff = high -low) %>%
  group_by(sent_rg_id, experiment, measure, metric) %>%
    summarise(m = mean(diff),
              sd = std.error(diff),
              lower = m - 1.96 * sd,
              upper = m + 1.96 * sd) %>%
    ungroup()


```

```{r}
# SPR Data

spr_clean_df = spr_df %>%
  rename(condition = type, item_id = group, word_nr = word_num, value = rt, subj = subject) %>%
  dplyr::select(condition, item_id, word_nr, value, subj, word) %>%
  mutate(word_nr = word_nr - 1) %>%
  merge(region_reference_df, by = c("item_id", "word", "word_nr")) %>%
  filter(! condition %in% c("filler", "practice")) %>%
  drop_na() %>%
  mutate(outlier = value > (mean(value) + 3 * sd(value))) %>%
  filter(outlier == F) %>%
  mutate(experiment = case_when(
    condition %in% c("adverb_high", "adverb_low") ~ "Adverb",
    condition %in% c("and_comma", "and_no_comma") ~ "Coordination",
    condition %in% c("relative_high", "relative_low") ~ "Relative Clause")
  ) %>%
  mutate(condition = case_when(
    condition %in% c("adverb_high", "relative_high", "and_no_comma") ~ "high",
    condition %in% c("adverb_low", "relative_low", "and_comma") ~ "low")
  ) %>%
  drop_na() %>%
  group_by(subj, item_id, condition, sent_rg_id, experiment) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
  mutate(measure = "SPR",
         metric = "go_past_time")

spr_agg_df = spr_clean_df %>%
    group_by(item_id, condition, sent_rg_id, experiment, metric, measure) %>%
    summarise(value = mean(value)) %>%
  ungroup() %>%
  spread(condition, value) %>%
  mutate(diff = high -low) %>%
  drop_na() %>%
  group_by(sent_rg_id, experiment, measure, metric) %>%
    summarise(m = mean(diff),
              sd = std.error(diff),
              lower = m - 1.96 * sd,
              upper = m + 1.96 * sd) %>%
  ungroup()

spr_clean_df

```


```{r}
# Combine the MoTR, Eye Tracking, Maze and SPR data into a single dataframe!

comb_agg_df = rbind(motr_agg_df, eyetr_agg_df, gmaze_agg_df, spr_agg_df, amaze_agg_df)

comb_clean_df = rbind(motr_clean_df, gmaze_clean_df, spr_clean_df, amaze_clean_df)

comb_clean_df %>%
  filter(measure == "MoTR", metric == "FPReg") %>%
  filter(metric >= 0) %>%
  summarise(m = mean(value))

# View(comb_agg_df)
# View(comb_clean_df)

```

## Stats!


```{r, eval=FALSE}

# set priors
priors_rt <- c(
  prior(normal(6, 1), class = Intercept),
  prior(normal(0, 0.1), class = b, coef = condition),
  prior(normal(0, 0.5), class = sd),
  prior(normal(0, 0.5), class = sigma),
  prior(lkj(2), class = cor)
)

priors_FPReg <- c(
  # U shape, allow more extreme values (0 and 1), not the upside-down "U".
  prior(normal(-4, 4), class = Intercept),    # reported results using normal(0, 2), which is okay cuz do not change the posterior dramatically.
  prior(normal(0, 1), class = b, coef = condition),
  prior(cauchy(0, 2), class = sd),
  prior(lkj(2), class = cor)
)

stats_df = data.frame()

for(exp in c("Coordination", "Relative Clause", "Adverb")) {

  for(met in c("gaze_duration", "go_past_time", "total_duration", "FPReg")){
    
    for(mes in c("MoTR", "G-Maze", "A-Maze", "SPR")) {

      for(i in -1:2) {
        
        temp_df = comb_clean_df %>% filter(metric == met, measure == mes, experiment == exp, sent_rg_id == i) %>%
          mutate(item_id = as.factor(item_id), subj = as.factor(subj)) %>%
          mutate(item_id = as.factor(item_id)) %>%
          mutate(condition = if_else(condition == "high", 1, 0))
        
        if(nrow(temp_df) > 0) {
          
          print(paste("Stats for:", exp, met, mes, sep = " "))

          if (met == "FPReg") {
            # model = glmer(value ~ condition + (condition || item_id), data = temp_df, family = "binomial")
            # pval = coef(summary(model))[8]
            
            model = brms::brm(value ~ condition + (condition | subj) + (condition | item_id), 
                              data = temp_df, 
                              family = bernoulli(link = "logit"), 
                              chains = 4,
                              file = paste0("./bayesian_models_lc/", exp, "_", met, "_", mes, "_", i), 
                              cores = 4, 
                              backend = "cmdstanr", 
                              prior = priors_FPReg)
            
            est = fixef(model)[2]
            sd = fixef(model)[4]
            upper = fixef(model)[8]
            lower = fixef(model)[6]
            
            # transform from logit space to probability space.
            alpha <- as_draws_df(model)$b_Intercept
            beta <- as_draws_df(model)$b_condition
            diff <- plogis(alpha + beta) - plogis(alpha)
            stats_ms <- c(mean = mean(diff), quantile(diff, c(.025, .975)))
            mean_ms <- stats_ms[1]
            lower_95_ms <- stats_ms[2]
            upper_95_ms <- stats_ms[3]
            
          } else {
            # temp_df = temp_df %>% mutate(value = scale(value)) #scale real-valued numbers for lmer
            # model = lmer(value ~ condition + (condition || subj) + (condition || item_id), data = temp_df)
            # pval = coef(summary(model))[10]
            model = brms::brm(value ~ condition + (condition | subj) + (condition | item_id),
                              data = temp_df,
                              chains = 4,
                              family = lognormal(),
                              file = paste0("./bayesian_models_lc/", exp, "_", met, "_", mes, "_", i),
                              cores = 4,
                              backend = "cmdstanr",
                              prior = priors_rt)
              
            est = fixef(model)[2]
            sd = fixef(model)[4]
            upper = fixef(model)[8]
            lower = fixef(model)[6]
            
            # transform from log-normal space to normal ms space.
            alpha <- as_draws_df(model)$b_Intercept
            beta <- as_draws_df(model)$b_condition
            sigma <- as_draws_df(model)$sigma
            diff <- exp(alpha + beta + (sigma^2)/2) - exp(alpha + (sigma^2)/2)
            stats_ms <- c(mean = mean(diff), quantile(diff, c(.025, .975)))
            mean_ms <- stats_ms[1]
            lower_95_ms <- stats_ms[2]
            upper_95_ms <- stats_ms[3]
          }
          
          result_df = data.frame(experiment = exp, sent_rg_id = i, metric = met,  measure = mes, std_error = sd, estimate = est, lower_95 = lower,  upper_95 = upper, mean = mean_ms, lower_95_ms = lower_95_ms, upper_95_ms = upper_95_ms)
          #result_df = data.frame(experiment = exp, sent_rg_id = i, metric = met, measure = mes, pval=pval)
          stats_df = rbind(stats_df, result_df)
        }
      }
    }
  }
}

write.csv(stats_df, "../visualizations/stats_bayesian.csv")

```

# plotting
```{r}

stats_df_bayesian <- read.csv("../visualizations/stats_bayesian.csv")%>%
  dplyr::select(-estimate, -lower_95, -upper_95, -std_error) %>%
  rename(estimate_mean = mean)

plotting_df = merge(comb_agg_df, stats_df_bayesian, all=T, by = c("sent_rg_id", "metric", "experiment", "measure")) %>%
  mutate(sig = if_else(measure != "Eye Tracking" & (upper_95_ms < 0 | lower_95_ms > 0), T, F)) %>%
  mutate(cris = if_else(measure != "Eye Tracking" & sig == T, paste0("[",round(lower_95_ms, 2), ",\n", " ",round(upper_95_ms, 2),"]"), "")) %>%
  #mutate(sig = if_else(measure != "Eye Tracking" & (upper_95_ms < 0 | lower_95_ms > 0), paste("X", sep = ""), F)) %>%
  mutate(measure = factor(measure, levels = c("MoTR", "Eye Tracking", "A-Maze", "G-Maze", "SPR"))) %>%
  mutate(metric = factor(metric, levels = c("first_duration", "gaze_duration", "go_past_time", "total_duration", "FPReg"),
                         labels = c("First Duration", "Gaze Duration", "Go Past Time", "Total Duration", "Regression Prob"))) %>%
  filter(metric != "First Duration")

```

```{r}
# This bit is just used for printing out the stats so they can be copied into the latex text in overleaf.
# I change the parameters to just print out different things.
stats_df_bayesian %>%
  mutate(estimate_mean = round(estimate_mean, digits=2),
         lower_95_ms = round(lower_95_ms, digits=2),
         upper_95_ms = round(upper_95_ms, digits=2)) %>%
  filter(measure == "A-Maze") %>%
  filter(experiment == "Coordination") %>%
  filter(sent_rg_id == 0)

```


```{r}

# PLOTTING FOR ONLY MOTR AND EYE TRACKING

plotting_df %>%
  filter(measure == "MoTR" | measure == "Eye Tracking") %>%
  ggplot(aes(x = sent_rg_id, y = m, color = measure, linetype = measure)) +
    geom_hline(yintercept = 0, color = "blue") +
    geom_point() +
    geom_errorbar(aes(ymax = upper, ymin = lower), width = 0.1) +
    geom_line() +
    geom_text(aes(label = cris, y = if_else(metric == "Regression Prob", 0.13, 190) ), size = 1.8) +
    geom_text(aes(x = 0, y = if_else(metric == "Regression Prob", 0.15, 220), label=""), show.legend = FALSE) +
  scale_color_manual(values = c("#000000", "#2eccc1")) +
  coord_cartesian(xlim = c(-1.25, 2.25)) +
  ylab("Difference in RTs (ms) Between Conditions") +
  xlab("Sentence Region") +
  scale_x_continuous(breaks = c(-1, 0, 1, 2), labels= c ("Pre-Critical", "Critical", "Critical +1", "Critcal +2")) +
  labs(color = "", linetype = "") +
  facet_wrap(experiment~metric, scales="free_y", nrow = 3) +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    panel.grid.minor = element_blank()
  )

ggsave(paste0("../visualization/target_results_cris", rate, ".pdf"), device="pdf", width = 8, height = 5.5)

```

```{r}

library(viridis)

estimate_plotting_df = stats_df_bayesian %>%
  mutate(measure = factor(measure, levels = c("MoTR", "Eye Tracking", "A-Maze", "G-Maze", "SPR"))) %>%
  mutate(metric = factor(metric, levels = c("first_duration", "gaze_duration", "go_past_time", "total_duration", "FPReg"),
                         labels = c("First Duration", "Gaze Duration", "Go Past Time", "Total Duration", "Regression Prob"))) %>%
  mutate(mm_label = if_else(measure == "MoTR", paste0("(",metric,")"), "")) %>%
  mutate(mm_label = paste(measure, mm_label)) %>%
  mutate(mm_label = factor(mm_label, levels = c("MoTR (Gaze Duration)", "MoTR (Go Past Time)", "MoTR (Total Duration)", "MoTR (Regression Prob)", "SPR ", "G-Maze ", "A-Maze "))) %>%
  mutate(sent_rg_id = factor(sent_rg_id, levels = c("-1", "0", "1", "2"),
                         labels = c("Pre-Critical", "Critical", "Critical +1", "Critcal +2")))

estimate_plotting_df %>%
  filter(mm_label != "MoTR (Regression Prob)") %>%
  ggplot(aes(y = sent_rg_id, x = estimate_mean, color = sent_rg_id)) +
    geom_vline(xintercept = 0, color = "green") +
    geom_point(position = position_dodge(width = 0.8)) +
    geom_errorbar(aes(xmin = lower_95_ms, xmax = upper_95_ms), width = 0, position = position_dodge(width = 0.8)) +
    facet_grid(mm_label ~ experiment, scales = "free_x") +
    scale_colour_manual(values = c("#22455b", "#35698c", "#458ab7", "#59b0ea")) +
    #scale_fill_gradient(low = "green", high="blue") +
    labs(color = "Sentence Region") +
    xlab("Estimate Mean (of High Attachment / No-Comma)") +
  theme(
    legend.position = "bottom",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    strip.text.y = element_text(angle = 0),
    axis.title.y = element_blank(),
    strip.text.x = element_blank(),
    strip.background.y = element_rect(fill = "white")
  )

ggsave(paste0("../visualizations/model_estimates", rate, ".pdf"), device="pdf", width = 8, height =5)

```


```{r}

estimate_plotting_df %>%
  filter(mm_label == "MoTR (Regression Prob)") %>%
  ggplot(aes(y = sent_rg_id, x = estimate_mean, color = sent_rg_id)) +
    geom_vline(xintercept = 0, color = "green") +
    geom_point(position = position_dodge(width = 0.8)) +
    geom_errorbar(aes(xmin = lower_95_ms, xmax = upper_95_ms), width = 0, position = position_dodge(width = 0.8)) +
    facet_grid(mm_label ~ experiment, scales = "free_x") +
    scale_colour_manual(values = c("#22455b", "#35698c", "#458ab7", "#59b0ea")) +
    #scale_fill_gradient(low = "green", high="blue") +
    labs(color = "Sentence Region") +
    xlab("Estimate Mean (of High Attachment / No-Comma)") +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    strip.text.y = element_text(angle = 0),
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    strip.background.y = element_rect(fill = "white")
  )

ggsave(paste0("../visualizations/model_estimates_regression", rate, ".pdf"), device="pdf", width = 8, height =1.2)


```


```{r}

# COMPARISON BETWEEN ALL MEASURES

plotting_df %>%
  group_by(experiment) %>%
    mutate(pval_y = max(upper)) %>%
  ungroup() %>%
  filter(metric == "Go Past Time") %>%
  filter(measure != "Eye Tracking") %>%
  ggplot(aes(x = sent_rg_id, y = m, color = measure)) +
    geom_hline(yintercept = 0, color = "blue") +
    geom_point() +
    geom_errorbar(aes(ymax = upper, ymin = lower), width = 0.1) +
    geom_line() +
    geom_text(aes(label = cris, y = pval_y + 60), color = "black", size = 1.8) +
    geom_text(aes(x = 0, y = pval_y + 100, label=""), show.legend = FALSE) +
  coord_cartesian(xlim = c(-1.25, 2.25)) +
  ylab("Difference in RTs (ms) Between Conditions") +
  xlab("Sentence Region") +
  scale_x_continuous(breaks = c(-1, 0, 1, 2), labels= c("Pre-Critical", "Critical", "Critical +1", "Critcal +2")) +
  labs(color = "", linetype = "") +
  facet_grid(experiment~measure, scales = "free_y") +
  theme(
    legend.position = "right",
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    panel.grid.minor = element_blank()
  )


ggsave(paste0("../visualizations/target_comp_cris", rate, ".pdf"), device="pdf", width = 8, height = 4.5)

```



